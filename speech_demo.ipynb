{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d2807b3",
   "metadata": {},
   "source": [
    "## Context\n",
    "### Business value for customers \n",
    "Gen AI driven solution leads to almost 50% cost savings.\n",
    "### TAM in India \n",
    "### Current Adoption\n",
    "#### Global Success Stories\n",
    "#### Success Stories in India\n",
    "#### Recommended Architecture\n",
    "#### BDM decks\n",
    "#### TDM decks\n",
    "#### Accelerators\n",
    "#### Blogs\n",
    "#### Existing Demos\n",
    "#### New Demo\n",
    "#### Open Issues Currently In Progress\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebbac4b",
   "metadata": {},
   "source": [
    "https://openai.com/index/hello-gpt-4o/\n",
    "https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/fast-transcription-public-preview-in-azure-ai-speech/ba-p/4108720"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ac4129",
   "metadata": {},
   "source": [
    "# Voice BOT \n",
    "## The old way:\n",
    "1. Sales Agent Persona - generates response using Open AI \n",
    "2. Response is converted to Speech \n",
    "3. Customer Reverts in audio \n",
    "4. Speech is converted to text - Average time for 1 + 2 + 4 is 5.4 s with GPT4 and 2.8 with GPT-3.5\n",
    "5. Back to step 1\n",
    "## The new way:\n",
    "1. Sales Agent Persona - generates audio response using Open AI - average expected time 320ms\n",
    "2. Customer Reverts in audio\n",
    "3. Back to step 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7820a6",
   "metadata": {},
   "source": [
    "Latency Reduction \n",
    "1. Streaming \n",
    "2. Fast Transcription \n",
    "3. Compression of audio - increased speed of words spoken\n",
    "4. Containers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acb9443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f47608f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from azure.cognitiveservices.speech import audio\n",
    "import simpleaudio as sa\n",
    "import io\n",
    "from pydub import AudioSegment\n",
    "import gradio as gr\n",
    "from io import BytesIO\n",
    "import tempfile\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "import wave\n",
    "\n",
    "from speech_demo_set_default_prompts import set_default_prompts_loan\n",
    "from speech_demo_set_default_prompts import set_default_prompts_ecom \n",
    "from speech_demo_gen_avatars import gen_dalle_img\n",
    "from speech_demo_get_conv_summary import get_summary\n",
    "from speech_demo_openai_response import get_openai_resp_text_audio, final_segment\n",
    "from speech_demo_human_response import get_human_resp_text_audio\n",
    "import io\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from pydub import AudioSegment, silence\n",
    "import simpleaudio as sa\n",
    "import threading\n",
    "import asyncio\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "speech_ep = os.getenv('SPEECH_EP')\n",
    "speech_key = os.getenv('SPEECH_KEY')\n",
    "speech_region = os.getenv('SPEECH_REGION')\n",
    "\n",
    "summary_prompt = \"\"\n",
    "person1_prompt = \"\"\n",
    "person2_prompt = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7686f2fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae389595",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gen_dalle_img(\"ecom\",\"persona2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e056dbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dalle_img_all(theme):\n",
    "    img1 = gen_dalle_img(theme,\"persona1\")\n",
    "    img2 = gen_dalle_img(theme,\"persona2\")\n",
    "    return img1, img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f54a93d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "async def main(language, agent_msgs, customer_msgs, response_mode):\n",
    "    #global person1_prompt\n",
    "    #global person2_prompt\n",
    "    #global agent_msgs\n",
    "    #global customer_msgs\n",
    "    i = 0\n",
    "    #agent_msgs = [{\"role\":\"system\",\"content\":person1_prompt}]\n",
    "    #customer_msgs = [{\"role\":\"system\",\"content\":person2_prompt}]\n",
    "    while i < 10:\n",
    "        print(\"Calling agent conversation\")\n",
    "        #print(agent_msgs)\n",
    "        await get_openai_resp_text_audio(agent_msgs, customer_msgs, language, True)\n",
    "        if \"Thank\" in agent_msgs[-1][\"content\"]:\n",
    "            print(\"Conversation over!\")\n",
    "            break\n",
    "        if \"thank\" in agent_msgs[-1][\"content\"]:\n",
    "            print(\"Conversation over!\")\n",
    "            break\n",
    "        if \"धन्यवाद\" in agent_msgs[-1][\"content\"]:\n",
    "            print(\"Conversation over!\")\n",
    "            break\n",
    "        print(\"Calling customer conversation\")\n",
    "        \n",
    "        if response_mode == \"Customer Speaks\":\n",
    "            # Process the audio input from the user\n",
    "            wav_file = f\"customer_response_{i}.wav\"\n",
    "            if language == \"English\":\n",
    "                lang = \"en-IN\"\n",
    "            else:\n",
    "                lang = \"hi-IN\"\n",
    "            customer_response = get_human_resp_text_audio(lang, wav_file)\n",
    "            agent_msgs.append({\"role\": \"user\", \"content\": customer_response})\n",
    "        else:\n",
    "            await get_openai_resp_text_audio(agent_msgs, customer_msgs, language, False)\n",
    "            \n",
    "        i += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "666d9f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_script(language, additional_prompt1, additional_prompt2, response_mode):\n",
    "    #global agent_msgs, customer_msgs\n",
    "    global final_segment\n",
    "    #global summary_prompt\n",
    "    \n",
    "    #person1_prompt, person2_prompt = set_prompt(language, theme)\n",
    "    agent_msgs = [{\"role\":\"system\", \"content\": additional_prompt1}]\n",
    "    customer_msgs = [{\"role\":\"system\", \"content\": additional_prompt2}]\n",
    "\n",
    "    \n",
    "    try:\n",
    "        import nest_asyncio\n",
    "        nest_asyncio.apply()\n",
    "    except ImportError:\n",
    "        pass\n",
    "\n",
    "    loop = asyncio.new_event_loop()\n",
    "    asyncio.set_event_loop(loop)\n",
    "    loop.run_until_complete(main(language, agent_msgs, customer_msgs, response_mode))\n",
    "    \n",
    "    final_segment.export(\"persona.wav\", format=\"wav\")\n",
    "    summary = get_summary(language, agent_msgs)\n",
    "    return summary, \"persona.wav\"\n",
    "\n",
    "\n",
    "def run_main_loop(language, additional_prompt1, additional_prompt2, response_mode):\n",
    "    return run_script(language, additional_prompt1, additional_prompt2, response_mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c04b93a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling agent conversation\n",
      "Received text chunk: Hello\n",
      "Received text chunk: !\n",
      "Received text chunk:  Are\n",
      "Received text chunk:  you\n",
      "Received text chunk:  interested\n",
      "Received text chunk:  in\n",
      "Received text chunk:  hearing\n",
      "Received text chunk:  about\n",
      "Received text chunk:  a\n",
      "Received text chunk:  new\n",
      "Received text chunk:  offer\n",
      "Received text chunk:  we\n",
      "Received text chunk:  have\n",
      "Received text chunk: ?\n",
      "Speech synthesized for text [Hello!]\n",
      "Speech synthesized for text [Are you interested in hearing about a new offer we have?]\n",
      "Calling customer conversation\n",
      "no callback\n",
      "Monitoring microphone... Start speaking to begin transcription.\n",
      "Speech detected, starting transcription...\n",
      "SESSION STARTED: SessionEventArgs(session_id=be3f767f4da44c0185237a7ec07295d8)\n",
      "Recording... Press Ctrl+C to stop.\n",
      "True no\n",
      "True no i\n",
      "True no i am kind of\n",
      "True no i am kind of busy\n",
      "True no i am kind of busy right now\n",
      "Recognized: False No, I am kind of busy right now.\n",
      "SESSION STOPPED: SessionEventArgs(session_id=be3f767f4da44c0185237a7ec07295d8)\n",
      "Calling agent conversation\n",
      "Received text chunk: I\n",
      "Received text chunk:  understand\n",
      "Received text chunk: .\n",
      "Received text chunk:  May\n",
      "Received text chunk:  I\n",
      "Received text chunk:  ask\n",
      "Received text chunk:  if\n",
      "Received text chunk:  you\n",
      "Received text chunk:  regularly\n",
      "Received text chunk:  order\n",
      "Received text chunk:  certain\n",
      "Received text chunk:  products\n",
      "Received text chunk:  from\n",
      "Received text chunk:  us\n",
      "Received text chunk: ?\n",
      "Speech synthesized for text [I understand.]\n",
      "Speech synthesized for text [May I ask if you regularly order certain products from us?]\n",
      "Calling customer conversation\n",
      "no callback\n",
      "Monitoring microphone... Start speaking to begin transcription.\n",
      "Speech detected, starting transcription...\n",
      "SESSION STARTED: SessionEventArgs(session_id=933b874dc29b4173af5d5416ddb5eea5)\n",
      "Recording... Press Ctrl+C to stop.\n",
      "True yeah\n",
      "True yeah i\n",
      "True yeah i do\n",
      "True yeah i do order\n",
      "True yeah i do order bunch of things\n",
      "True yeah i do order bunch of things every week\n",
      "Recognized: False Yeah, I do order bunch of things every week.\n",
      "CANCELED: SpeechRecognitionCanceledEventArgs(session_id=933b874dc29b4173af5d5416ddb5eea5, result=SpeechRecognitionResult(result_id=befa4eb1f42c49c39503018a7cc46c6e, text=\"\", reason=ResultReason.Canceled))\n",
      "SESSION STOPPED: SessionEventArgs(session_id=933b874dc29b4173af5d5416ddb5eea5)\n",
      "Calling agent conversation\n",
      "Received text chunk: Great\n",
      "Received text chunk: !\n",
      "Received text chunk:  Would\n",
      "Received text chunk:  you\n",
      "Received text chunk:  be\n",
      "Received text chunk:  interested\n",
      "Received text chunk:  in\n",
      "Received text chunk:  creating\n",
      "Received text chunk:  a\n",
      "Received text chunk:  subscription\n",
      "Received text chunk:  to\n",
      "Received text chunk:  receive\n",
      "Received text chunk:  discounts\n",
      "Received text chunk:  on\n",
      "Received text chunk:  your\n",
      "Received text chunk:  regular\n",
      "Received text chunk:  orders\n",
      "Received text chunk: ?\n",
      "Speech synthesized for text [Great!]\n",
      "Speech synthesized for text [Would you be interested in creating a subscription to receive discounts on your regular orders?]\n",
      "Calling customer conversation\n",
      "no callback\n",
      "Monitoring microphone... Start speaking to begin transcription.\n",
      "Speech detected, starting transcription...\n",
      "SESSION STARTED: SessionEventArgs(session_id=6d6d5f652d864d0083c56f9a15bf2fbf)\n",
      "Recording... Press Ctrl+C to stop.\n",
      "True what\n",
      "True what kind of\n",
      "True what kind of discount\n",
      "True what kind of discount are you offering\n",
      "Recognized: False What kind of discount are you offering?\n",
      "SESSION STOPPED: SessionEventArgs(session_id=6d6d5f652d864d0083c56f9a15bf2fbf)\n",
      "Calling agent conversation\n",
      "Received text chunk: We\n",
      "Received text chunk:  are\n",
      "Received text chunk:  offering\n",
      "Received text chunk:  a\n",
      "Received text chunk:  \n",
      "Received text chunk: 20\n",
      "Received text chunk: %\n",
      "Received text chunk:  discount\n",
      "Received text chunk:  on\n",
      "Received text chunk:  your\n",
      "Received text chunk:  regular\n",
      "Received text chunk:  orders\n",
      "Received text chunk:  if\n",
      "Received text chunk:  you\n",
      "Received text chunk:  subscribe\n",
      "Received text chunk: .\n",
      "Speech synthesized for text [We are offering a 20% discount on your regular orders if you subscribe.]\n",
      "Calling customer conversation\n",
      "no callback\n",
      "Monitoring microphone... Start speaking to begin transcription.\n",
      "Speech detected, starting transcription...\n",
      "SESSION STARTED: SessionEventArgs(session_id=2098219cc6404a31a9d573d237da70e0)\n",
      "Recording... Press Ctrl+C to stop.\n",
      "True no that\n",
      "True no that is not\n",
      "True no that is not exciting at all\n",
      "Recognized: False No, that is not exciting at all.\n",
      "CANCELED: SpeechRecognitionCanceledEventArgs(session_id=2098219cc6404a31a9d573d237da70e0, result=SpeechRecognitionResult(result_id=1a49b0ebec1c43c8ab9ff1511e5053c8, text=\"\", reason=ResultReason.Canceled))\n",
      "SESSION STOPPED: SessionEventArgs(session_id=2098219cc6404a31a9d573d237da70e0)\n",
      "Calling agent conversation\n",
      "Received text chunk: How\n",
      "Received text chunk:  about\n",
      "Received text chunk:  a\n",
      "Received text chunk:  \n",
      "Received text chunk: 25\n",
      "Received text chunk: %\n",
      "Received text chunk:  discount\n",
      "Received text chunk:  if\n",
      "Received text chunk:  you\n",
      "Received text chunk:  subscribe\n",
      "Received text chunk:  for\n",
      "Received text chunk:  \n",
      "Received text chunk: 6\n",
      "Received text chunk:  months\n",
      "Received text chunk: ?\n",
      "Speech synthesized for text [How about a 25% discount if you subscribe for 6 months?]\n",
      "Calling customer conversation\n",
      "no callback\n",
      "Monitoring microphone... Start speaking to begin transcription.\n",
      "Speech detected, starting transcription...\n",
      "SESSION STARTED: SessionEventArgs(session_id=96fe294f30a64607a511152a21410071)\n",
      "Recording... Press Ctrl+C to stop.\n",
      "True no i dont\n",
      "True no i dont want\n",
      "True no i dont want to commit\n",
      "True no i dont want to commit for\n",
      "True no i dont want to commit for 6 months\n",
      "Recognized: False No I dont want to commit for 6 months.\n",
      "SESSION STOPPED: SessionEventArgs(session_id=96fe294f30a64607a511152a21410071)\n",
      "Calling agent conversation\n",
      "Received text chunk: If\n",
      "Received text chunk:  you\n",
      "Received text chunk:  subscribe\n",
      "Received text chunk:  for\n",
      "Received text chunk:  \n",
      "Received text chunk: 1\n",
      "Received text chunk:  year\n",
      "Received text chunk: ,\n",
      "Received text chunk:  you'll\n",
      "Received text chunk:  get\n",
      "Received text chunk:  a\n",
      "Received text chunk:  \n",
      "Received text chunk: 50\n",
      "Received text chunk: %\n",
      "Received text chunk:  discount\n",
      "Received text chunk:  at\n",
      "Received text chunk:  JW\n",
      "Received text chunk:  Marriott\n",
      "Received text chunk:  Phuket\n",
      "Received text chunk: .\n",
      "Speech synthesized for text [If you subscribe for 1 year,]\n",
      "Speech synthesized for text [you'll get a 50% discount at JW Marriott Phuket.]\n",
      "Calling customer conversation\n",
      "no callback\n",
      "Monitoring microphone... Start speaking to begin transcription.\n",
      "Speech detected, starting transcription...\n",
      "SESSION STARTED: SessionEventArgs(session_id=7ff656b7a5bd49a3a4cbd7231c1856bd)\n",
      "Recording... Press Ctrl+C to stop.\n",
      "True that is\n",
      "True that is super exciting\n",
      "True that is super exciting i\n",
      "True that is super exciting i take the offer\n",
      "Recognized: False That is super exciting. I take the offer.\n",
      "CANCELED: SpeechRecognitionCanceledEventArgs(session_id=7ff656b7a5bd49a3a4cbd7231c1856bd, result=SpeechRecognitionResult(result_id=c6d1c5c8ada0476f98cacf28bc31927c, text=\"\", reason=ResultReason.Canceled))\n",
      "SESSION STOPPED: SessionEventArgs(session_id=7ff656b7a5bd49a3a4cbd7231c1856bd)\n",
      "Calling agent conversation\n",
      "Received text chunk: Wonderful\n",
      "Received text chunk: !\n",
      "Received text chunk:  You\n",
      "Received text chunk:  will\n",
      "Received text chunk:  shortly\n",
      "Received text chunk:  receive\n",
      "Received text chunk:  confirmation\n",
      "Received text chunk:  of\n",
      "Received text chunk:  your\n",
      "Received text chunk:  subscription\n",
      "Received text chunk: .\n",
      "Received text chunk:  Thank\n",
      "Received text chunk:  you\n",
      "Received text chunk:  for\n",
      "Received text chunk:  choosing\n",
      "Received text chunk:  our\n",
      "Received text chunk:  service\n",
      "Received text chunk: .\n",
      "Speech synthesized for text [Wonderful!]\n",
      "Speech synthesized for text [You will shortly receive confirmation of your subscription.]\n",
      "Speech synthesized for text [Thank you for choosing our service.]\n",
      "Conversation over!\n",
      "[{'role': 'system', 'content': 'Create summary of the given conversation'}, {'role': 'user', 'content': 'assistant:Hello! Are you interested in hearing about a new offer we have?\\n user:No, I am kind of busy right now.\\n assistant:I understand. May I ask if you regularly order certain products from us?\\n user:No, I am kind of busy right now. Yeah, I do order bunch of things every week.\\n assistant:Great! Would you be interested in creating a subscription to receive discounts on your regular orders?\\n user:No, I am kind of busy right now. Yeah, I do order bunch of things every week. What kind of discount are you offering?\\n assistant:We are offering a 20% discount on your regular orders if you subscribe.\\n user:No, I am kind of busy right now. Yeah, I do order bunch of things every week. What kind of discount are you offering? No, that is not exciting at all.\\n assistant:How about a 25% discount if you subscribe for 6 months?\\n user:No, I am kind of busy right now. Yeah, I do order bunch of things every week. What kind of discount are you offering? No, that is not exciting at all. No I dont want to commit for 6 months.\\n assistant:If you subscribe for 1 year, youll get a 50% discount at JW Marriott Phuket.\\n user:No, I am kind of busy right now. Yeah, I do order bunch of things every week. What kind of discount are you offering? No, that is not exciting at all. No I dont want to commit for 6 months. That is super exciting. I take the offer.\\n assistant:Wonderful! You will shortly receive confirmation of your subscription. Thank you for choosing our service.'}]\n"
     ]
    }
   ],
   "source": [
    "def set_prompt(language, theme):\n",
    "    #language = \"Hindi\"\n",
    "    if theme == \"ecom\":\n",
    "        person1_prompt, person2_prompt = set_default_prompts_ecom(language)\n",
    "    else:\n",
    "        person1_prompt, person2_prompt = set_default_prompts_loan(language)\n",
    "    img1, img2 = gen_dalle_img_all(theme)\n",
    "    return person1_prompt, person2_prompt, img1, img2 \n",
    "\n",
    "\n",
    "with gr.Blocks() as iface:\n",
    "    with gr.Row():\n",
    "        language = gr.Dropdown(choices=[\"English\", \"Hindi\"], label=\"Select Language\")\n",
    "        theme = gr.Dropdown(choices=[\"ecom\", \"loan\"], label=\"Select Theme\")\n",
    "        lang_button = gr.Button(\"Set Prompts\")\n",
    "    with gr.Row():\n",
    "        additional_prompt1 = gr.Textbox(lines=5, placeholder=\"Additional Prompt 1\", label=\"Additional Prompt 1\")\n",
    "        additional_prompt2 = gr.Textbox(lines=5, placeholder=\"Additional Prompt 2\", label=\"Additional Prompt 2\")\n",
    "    with gr.Row():\n",
    "        response_mode = gr.Dropdown(choices=[\"Customer Speaks\", \"OpenAI Generates\"], label=\"Response Mode\")\n",
    "        run_button = gr.Button(\"Run\")\n",
    "    with gr.Row():\n",
    "            with gr.Column():\n",
    "                person1_image = gr.Image(label=\"Person 1 Image\")\n",
    "            with gr.Column():\n",
    "                summary = gr.Textbox(lines=10, placeholder=\"Conversation Summary\", label=\"Conversation Summary\")\n",
    "            with gr.Column():\n",
    "                person2_image = gr.Image(label=\"Person 2 Image\")\n",
    "                \n",
    "\n",
    "    with gr.Row():     \n",
    "            person1_audio = gr.Audio(label=\"Person 1 Audio\")\n",
    "            person2_audio = gr.Audio(label=\"Person 2 Audio\")\n",
    "                \n",
    "    \n",
    "    \n",
    "       \n",
    "    lang_button.click(fn=set_prompt, inputs=[language, theme], outputs=[additional_prompt1, additional_prompt2, person1_image, person2_image])\n",
    "    run_button.click(fn=run_main_loop, inputs=[language, additional_prompt1, additional_prompt2, response_mode], outputs=[summary, person1_audio])\n",
    "    \n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc14fa2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeeb9e52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cd1433",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
