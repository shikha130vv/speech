{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21c1bfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a2e9c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RECOGNIZED: SpeechRecognitionEventArgs(session_id=23b4f267249f4c199172833a796c2c2a, result=SpeechRecognitionResult(result_id=c5991f8e1b5b4f0694d1791f2f1c5bda, text=\"नमस्ते मेन पूजा बजाज फनैन्स के आपकी वर्चुअल असिस्टेंट आपको लोन का रेक्विरेमेंट है क्या?\", reason=ResultReason.RecognizedSpeech))\n",
      "0:00:02.210073\n",
      "result:{'RecognitionStatus': 'Success', 'Offset': 1100000, 'Duration': 70000000, 'NBest': [{'Confidence': 0.74739945, 'Lexical': 'नमस्ते मेन पूजा बजाज फनैन्स के आपकी वर्चुअल असिस्टेंट आपको लोन का रेक्विरेमेंट है क्या', 'ITN': 'नमस्ते मेन पूजा बजाज फनैन्स के आपकी वर्चुअल असिस्टेंट आपको लोन का रेक्विरेमेंट है क्या', 'MaskedITN': 'नमस्ते मेन पूजा बजाज फनैन्स के आपकी वर्चुअल असिस्टेंट आपको लोन का रेक्विरेमेंट है क्या', 'Display': 'नमस्ते मेन पूजा बजाज फनैन्स के आपकी वर्चुअल असिस्टेंट आपको लोन का रेक्विरेमेंट है क्या?'}], 'DisplayText': 'नमस्ते मेन पूजा बजाज फनैन्स के आपकी वर्चुअल असिस्टेंट आपको लोन का रेक्विरेमेंट है क्या?'}\n",
      "0:00:02.066031\n",
      "SESSION STARTED: SessionEventArgs(session_id=0c251808869a4967857ab682d49c20e3)\n",
      "Done\n",
      "Time taken as measured from calling function: 0:00:02.109268\n",
      "Recognition latency: 616 ms\n",
      "नमस्ते मेन पूजा बजाज फनैन्स के आपकी वर्चुअल असिस्टेंट आपको लोन का रेक्विरेमेंट है क्या?\n",
      "0:00:00.456490\n",
      "SESSION STOPPED: SessionEventArgs(session_id=0c251808869a4967857ab682d49c20e3)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "#!pip install nest_asyncio\n",
    "\n",
    "\n",
    "# In[66]:\n",
    "\n",
    "\n",
    "import wave\n",
    "import time\n",
    "from datetime import datetime\n",
    "import concurrent.futures\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "import os\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import uuid\n",
    "import requests\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "from azure.cognitiveservices.speech import AudioDataStream, SpeechConfig, SpeechRecognizer, AudioConfig\n",
    "from azure.cognitiveservices.speech.audio import PushAudioInputStream, AudioStreamFormat\n",
    "phrases_list = [\"ई-एम-आई\", \"ब्याज दर\", \"तिरसठ\", \"इक्यावन\", \"उनचालीस\", \"सत्ताईस\", \"महीने\", \"उनतालीस\"]\n",
    "\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "\n",
    "speech_ep = os.getenv('SPEECH_EP')\n",
    "speech_key = os.getenv('SPEECH_KEY')\n",
    "\n",
    "speech_region = os.getenv('SPEECH_REGION')\n",
    "audiofile = \"trimmed_16k_41.wav\"\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[67]:\n",
    "\n",
    "\n",
    "def speech_recognize_continuous_from_file(audiofile, lang):\n",
    "\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=speech_region)\n",
    "    speech_config.output_format = speechsdk.OutputFormat.Detailed\n",
    "    speech_config.speech_recognition_language=lang\n",
    "    audio_config = speechsdk.audio.AudioConfig(filename=audiofile)\n",
    "\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "    \n",
    "    \n",
    "    done = False\n",
    "\n",
    "    def stop_cb(evt: speechsdk.SessionEventArgs):\n",
    "        \"\"\"callback that signals to stop continuous recognition upon receiving an event `evt`\"\"\"\n",
    "        nonlocal done\n",
    "        done = True\n",
    "\n",
    "    speech_recognizer.recognized.connect(lambda evt: print('RECOGNIZED: {}'.format(evt)))\n",
    "    speech_recognizer.session_stopped.connect(stop_cb)\n",
    "    speech_recognizer.canceled.connect(stop_cb)\n",
    "\n",
    "    speech_recognizer.start_continuous_recognition_async()\n",
    "    while not done:\n",
    "        time.sleep(.001)\n",
    "\n",
    "    speech_recognizer.stop_continuous_recognition_async()\n",
    "   \n",
    "\n",
    "\n",
    "# In[68]:\n",
    "\n",
    "\n",
    "start_time = datetime.now()\n",
    "result = speech_recognize_continuous_from_file(\"trimmed_16k_41.wav\", \"hi-IN\")\n",
    "end_time = datetime.now()\n",
    "print(end_time-start_time)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[69]:\n",
    "\n",
    "\n",
    "def trans_with_api_code(audio_file_path, language):\n",
    "    endpoint = f\"https://{speech_region}.stt.speech.microsoft.com/speech/recognition/conversation/cognitiveservices/v1?language={language}&format=detailed\"\n",
    "\n",
    "    session_id = str(uuid.uuid4()).replace('-', '')\n",
    "\n",
    "    headers = {\n",
    "        'Ocp-Apim-Subscription-Key': speech_key,\n",
    "        'Content-Type': 'audio/wav; samplerate=8000',\n",
    "        'Accept': 'application/json',\n",
    "        'X-ConnectionId': session_id\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        with open(audio_file_path, \"rb\") as audio_file:\n",
    "            audio_data = audio_file.read()\n",
    "\n",
    "        request_body = {\n",
    "            \"recognitionParameters\": {\n",
    "                \"wordLevelConfidence\": True,\n",
    "                \"profanityFilterMode\": \"Masked\",\n",
    "                \"grammar\": {\n",
    "                    \"externalPhrases\": phrases_list\n",
    "                }\n",
    "            }\n",
    "\n",
    "        }\n",
    "\n",
    "        start_time = datetime.now()\n",
    "        response = requests.post(endpoint, headers=headers, data=audio_data, json=request_body)\n",
    "\n",
    "    \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            \n",
    "            print(f\"result:{result}\")\n",
    "        else:\n",
    "            print(\"error\", response.json())\n",
    "            \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "# In[70]:\n",
    "\n",
    "\n",
    "start_time = datetime.now()\n",
    "result = trans_with_api_code(\"trimmed_16k_41.wav\", \"hi-IN\")\n",
    "end_time = datetime.now()\n",
    "print(end_time-start_time)\n",
    "\n",
    "\n",
    "# In[50]:\n",
    "\n",
    "\n",
    "# Measuring latency: https://learn.microsoft.com/en-us/answers/questions/752263/azure-speech-to-text-how-can-sdk-client-know-the-l\n",
    "\n",
    "\n",
    "# In[75]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "681b753d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SESSION STARTED: SessionEventArgs(session_id=c4532a9686604d81942b80d753e46626)\n",
      "Done\n",
      "Recognition latency: 2261 ms\n",
      "नमस्ते मेन पूजा बजाज फनैन्स के आपकी वर्चुअल असिस्टेंट आपको लोन का रेक्विरेमेंट है क्या?\n",
      "0:00:03.363288\n",
      "Time taken as measured from calling function: 0:00:03.379048\n",
      "SESSION STOPPED: SessionEventArgs(session_id=c4532a9686604d81942b80d753e46626)\n"
     ]
    }
   ],
   "source": [
    "segments = []\n",
    "def streaming_call_back(idx):\n",
    "    global segments\n",
    "    n_bytes = 6400 * 45\n",
    "    if len(segments) == 0:\n",
    "        file_path = \"trimmed_16k_41.wav\"\n",
    "        with wave.open(file_path, 'rb') as wav_fh:\n",
    "            while True:\n",
    "                frames = wav_fh.readframes(n_bytes // wav_fh.getsampwidth())\n",
    "                if not frames:\n",
    "                    break\n",
    "                segments.append(frames)\n",
    "    if idx < len(segments):\n",
    "        data = segments[idx]\n",
    "    if idx == len(segments) - 1:\n",
    "        next_idx = -1\n",
    "    else:\n",
    "        next_idx = idx + 1\n",
    "    \n",
    "    time.sleep(0.04)\n",
    "    start_time1 = datetime.now() \n",
    "    return {\"data\":data, \"next_idx\":next_idx, \"start_time\": start_time1}\n",
    "\n",
    "            \n",
    "def trans_with_streaming(streaming_call_back, lang, start_time=None):\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=speech_region)\n",
    "    speech_config.output_format = speechsdk.OutputFormat.Detailed\n",
    "    stream = speechsdk.audio.PushAudioInputStream()\n",
    "    audio_config = speechsdk.audio.AudioConfig(stream=stream)\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(language=lang, speech_config=speech_config, audio_config=audio_config)\n",
    "    \n",
    "    text = []\n",
    "    done=False\n",
    "    def handle_recognized(evt):\n",
    "        #This will give you confidence score\n",
    "        #print(evt.result.json)\n",
    "        if evt.result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "            \n",
    "            #print(start_time, end_time)\n",
    "            try:\n",
    "                latency = evt.result.properties[speechsdk.PropertyId.SpeechServiceResponse_RecognitionLatencyMs]\n",
    "        \n",
    "                print(f\"Recognition latency: {latency} ms\")\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "            text.append(evt.result.text)\n",
    "            print(evt.result.text)\n",
    "            end_time = datetime.now()\n",
    "            print(end_time-start_time)\n",
    "            nonlocal done\n",
    "            done = True\n",
    "        elif evt.result.reason == speechsdk.ResultReason.NoMatch:\n",
    "            print('NOMATCH: Speech could not be recognized.')\n",
    "\n",
    "    def handle_canceled(evt):\n",
    "        print('CANCELED: {}'.format(evt))\n",
    "        if evt.reason == speechsdk.CancellationReason.Error:\n",
    "            print('CANCELED: Error details - {}'.format(evt.error_details))\n",
    "        speech_recognizer.stop_continuous_recognition_async()\n",
    "    \n",
    "    \n",
    "    speech_recognizer.recognized.connect(handle_recognized)\n",
    "    speech_recognizer.session_started.connect(lambda evt: print('SESSION STARTED: {}'.format(evt)))\n",
    "    speech_recognizer.session_stopped.connect(lambda evt: print('SESSION STOPPED: {}'.format(evt)))\n",
    "    speech_recognizer.canceled.connect(handle_canceled)\n",
    "    \n",
    "\n",
    "    next_idx = 0\n",
    "    try:\n",
    "        speech_recognizer.start_continuous_recognition_async()\n",
    "        while next_idx >= 0:\n",
    "            resp = streaming_call_back(next_idx)\n",
    "            stream.write(resp[\"data\"])\n",
    "            next_idx = resp[\"next_idx\"]\n",
    "            start_time1 = resp[\"start_time\"]\n",
    "            #print(start_time)\n",
    "            #time.sleep(0.01)\n",
    "        \n",
    "            #stream.close()\n",
    "    except AssertionError as e:\n",
    "        print(f\"Audio format error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading audio file: {e}\")\n",
    "    finally:\n",
    "        print(\"Done\")\n",
    "        while not done:\n",
    "            time.sleep(0.001)\n",
    "        speech_recognizer.stop_continuous_recognition_async()\n",
    "\n",
    "    return ' '.join(text)\n",
    "\n",
    "\n",
    "# In[76]:\n",
    "\n",
    "\n",
    "start_time = datetime.now()\n",
    "trans_with_streaming(streaming_call_back, \"hi-IN\",start_time)\n",
    "end_time = datetime.now()\n",
    "print(f\"Time taken as measured from calling function: {end_time-start_time}\")\n",
    "\n",
    "\n",
    "# In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2791d458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2b20fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368122e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
