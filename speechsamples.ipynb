{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15fcf243",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# Copyright (c) Microsoft. All rights reserved.\n",
    "# Licensed under the MIT license. See LICENSE.md file in the project root for full license information.\n",
    "\"\"\"\n",
    "Speech recognition samples for the Microsoft Cognitive Services Speech SDK\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import string\n",
    "import time\n",
    "import threading\n",
    "import wave\n",
    "import utils\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "\n",
    "speech_ep = os.getenv('SPEECH_EP')\n",
    "speech_key = os.getenv('SPEECH_KEY')\n",
    "speech_region = os.getenv('SPEECH_REGION')\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    import azure.cognitiveservices.speech as speechsdk\n",
    "except ImportError:\n",
    "    print(\"\"\"\n",
    "    Importing the Speech SDK for Python failed.\n",
    "    Refer to\n",
    "    https://docs.microsoft.com/azure/cognitive-services/speech-service/quickstart-python for\n",
    "    installation instructions.\n",
    "    \"\"\")\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "\n",
    "# Set up the subscription info for the Speech Service:\n",
    "# Replace with your own subscription key and service region (e.g., \"westus\").\n",
    "speech_key, service_region = speech_key, speech_region\n",
    "\n",
    "# Specify the path to an audio file containing speech (mono WAV / PCM with a sampling rate of 16\n",
    "# kHz).\n",
    "weatherfilename = \"whatstheweatherlike.wav\"\n",
    "weatherfilenamemp3 = \"whatstheweatherlike.mp3\"\n",
    "weatherfilenamemulaw = \"whatstheweatherlike-mulaw.wav\"\n",
    "seasonsfilename = \"pronunciation_assessment_fall.wav\"\n",
    "\n",
    "\n",
    "def speech_recognize_once_from_mic():\n",
    "    \"\"\"performs one-shot speech recognition from the default microphone\"\"\"\n",
    "    # <SpeechRecognitionWithMicrophone>\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "    # Creates a speech recognizer using microphone as audio input.\n",
    "    # The default language is \"en-us\".\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config)\n",
    "\n",
    "    # Starts speech recognition, and returns after a single utterance is recognized. The end of a\n",
    "    # single utterance is determined by listening for silence at the end or until a maximum of 15\n",
    "    # seconds of audio is processed. It returns the recognition text as result.\n",
    "    # Note: Since recognize_once() returns only a single utterance, it is suitable only for single\n",
    "    # shot recognition like command or query.\n",
    "    # For long-running multi-utterance recognition, use start_continuous_recognition() instead.\n",
    "    result = speech_recognizer.recognize_once()\n",
    "\n",
    "    # Check the result\n",
    "    if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "        print(\"Recognized: {}\".format(result.text))\n",
    "    elif result.reason == speechsdk.ResultReason.NoMatch:\n",
    "        print(\"No speech could be recognized\")\n",
    "    elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = result.cancellation_details\n",
    "        print(\"Speech Recognition canceled: {}\".format(cancellation_details.reason))\n",
    "        if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "    # </SpeechRecognitionWithMicrophone>\n",
    "\n",
    "\n",
    "def speech_recognize_once_from_file():\n",
    "    \"\"\"performs one-shot speech recognition with input from an audio file\"\"\"\n",
    "    # <SpeechRecognitionWithFile>\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "    audio_config = speechsdk.audio.AudioConfig(filename=weatherfilename)\n",
    "    # Creates a speech recognizer using a file as audio input, also specify the speech language\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(\n",
    "        speech_config=speech_config, language=\"de-DE\", audio_config=audio_config)\n",
    "\n",
    "    # Starts speech recognition, and returns after a single utterance is recognized. The end of a\n",
    "    # single utterance is determined by listening for silence at the end or until a maximum of 15\n",
    "    # seconds of audio is processed. It returns the recognition text as result.\n",
    "    # Note: Since recognize_once() returns only a single utterance, it is suitable only for single\n",
    "    # shot recognition like command or query.\n",
    "    # For long-running multi-utterance recognition, use start_continuous_recognition() instead.\n",
    "    result = speech_recognizer.recognize_once()\n",
    "\n",
    "    # Check the result\n",
    "    if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "        print(\"Recognized: {}\".format(result.text))\n",
    "    elif result.reason == speechsdk.ResultReason.NoMatch:\n",
    "        print(\"No speech could be recognized: {}\".format(result.no_match_details))\n",
    "    elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = result.cancellation_details\n",
    "        print(\"Speech Recognition canceled: {}\".format(cancellation_details.reason))\n",
    "        if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "    # </SpeechRecognitionWithFile>\n",
    "\n",
    "\n",
    "def speech_recognize_once_from_file_with_detailed_recognition_results():\n",
    "    \"\"\"performs one-shot speech recognition with input from an audio file, showing detailed recognition results\n",
    "    including word-level timing \"\"\"\n",
    "    # <SpeechRecognitionFromFileWithDetailedRecognitionResults>\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "\n",
    "    # Ask for detailed recognition result\n",
    "    speech_config.output_format = speechsdk.OutputFormat.Detailed\n",
    "\n",
    "    # If you also want word-level timing in the detailed recognition results, set the following.\n",
    "    # Note that if you set the following, you can omit the previous line\n",
    "    #   \"speech_config.output_format = speechsdk.OutputFormat.Detailed\",\n",
    "    # since word-level timing implies detailed recognition results.\n",
    "    speech_config.request_word_level_timestamps()\n",
    "\n",
    "    audio_config = speechsdk.audio.AudioConfig(filename=weatherfilename)\n",
    "\n",
    "    # Creates a speech recognizer using a file as audio input, also specify the speech language\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(\n",
    "        speech_config=speech_config, language=\"en-US\", audio_config=audio_config)\n",
    "\n",
    "    # Starts speech recognition, and returns after a single utterance is recognized. The end of a\n",
    "    # single utterance is determined by listening for silence at the end or until a maximum of 15\n",
    "    # seconds of audio is processed. It returns the recognition text as result.\n",
    "    # Note: Since recognize_once() returns only a single utterance, it is suitable only for single\n",
    "    # shot recognition like command or query.\n",
    "    # For long-running multi-utterance recognition, use start_continuous_recognition() instead.\n",
    "    result = speech_recognizer.recognize_once()\n",
    "\n",
    "    # Check the result\n",
    "    if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "        print(\"Recognized: {}\".format(result.text))\n",
    "\n",
    "        # Time units are in hundreds of nanoseconds (HNS), where 10000 HNS equals 1 millisecond\n",
    "        print(\"Offset: {}\".format(result.offset))\n",
    "        print(\"Duration: {}\".format(result.duration))\n",
    "\n",
    "        # Now get the detailed recognition results from the JSON\n",
    "        json_result = json.loads(result.json)\n",
    "\n",
    "        # The first cell in the NBest list corresponds to the recognition results\n",
    "        # (NOT the cell with the highest confidence number!)\n",
    "        print(\"Detailed results - Lexical: {}\".format(json_result['NBest'][0]['Lexical']))\n",
    "        # ITN stands for Inverse Text Normalization\n",
    "        print(\"Detailed results - ITN: {}\".format(json_result['NBest'][0]['ITN']))\n",
    "        print(\"Detailed results - MaskedITN: {}\".format(json_result['NBest'][0]['MaskedITN']))\n",
    "        print(\"Detailed results - Display: {}\".format(json_result['NBest'][0]['Display']))\n",
    "\n",
    "        # Print word-level timing. Time units are HNS.\n",
    "        words = json_result['NBest'][0]['Words']\n",
    "        print(\"Detailed results - Word timing:\\nWord:\\tOffset:\\tDuration:\")\n",
    "        for word in words:\n",
    "            print(f\"{word['Word']}\\t{word['Offset']}\\t{word['Duration']}\")\n",
    "\n",
    "        # You can access alternative recognition results through json_result['NBest'][i], i=1,2,..\n",
    "\n",
    "    elif result.reason == speechsdk.ResultReason.NoMatch:\n",
    "        print(\"No speech could be recognized: {}\".format(result.no_match_details))\n",
    "    elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = result.cancellation_details\n",
    "        print(\"Speech Recognition canceled: {}\".format(cancellation_details.reason))\n",
    "        if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "    # </SpeechRecognitionFromFileWithDetailedRecognitionResults>\n",
    "\n",
    "\n",
    "def speech_recognize_once_compressed_input():\n",
    "    \"\"\"performs one-shot speech recognition with compressed input from an audio file\"\"\"\n",
    "    # <SpeechRecognitionWithCompressedFile>\n",
    "    class BinaryFileReaderCallback(speechsdk.audio.PullAudioInputStreamCallback):\n",
    "        def __init__(self, filename: str):\n",
    "            super().__init__()\n",
    "            self._file_h = open(filename, \"rb\")\n",
    "\n",
    "        def read(self, buffer: memoryview) -> int:\n",
    "            try:\n",
    "                size = buffer.nbytes\n",
    "                frames = self._file_h.read(size)\n",
    "\n",
    "                buffer[:len(frames)] = frames\n",
    "\n",
    "                return len(frames)\n",
    "            except Exception as ex:\n",
    "                print('Exception in `read`: {}'.format(ex))\n",
    "                raise\n",
    "\n",
    "        def close(self) -> None:\n",
    "            print('closing file')\n",
    "            try:\n",
    "                self._file_h.close()\n",
    "            except Exception as ex:\n",
    "                print('Exception in `close`: {}'.format(ex))\n",
    "                raise\n",
    "    # Creates an audio stream format. For an example we are using MP3 compressed file here\n",
    "    compressed_format = speechsdk.audio.AudioStreamFormat(compressed_stream_format=speechsdk.AudioStreamContainerFormat.MP3)\n",
    "    callback = BinaryFileReaderCallback(filename=weatherfilenamemp3)\n",
    "    stream = speechsdk.audio.PullAudioInputStream(stream_format=compressed_format, pull_stream_callback=callback)\n",
    "\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "    audio_config = speechsdk.audio.AudioConfig(stream=stream)\n",
    "\n",
    "    # Creates a speech recognizer using a file as audio input, also specify the speech language\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config, audio_config)\n",
    "\n",
    "    # Starts speech recognition, and returns after a single utterance is recognized. The end of a\n",
    "    # single utterance is determined by listening for silence at the end or until a maximum of 15\n",
    "    # seconds of audio is processed. It returns the recognition text as result.\n",
    "    # Note: Since recognize_once() returns only a single utterance, it is suitable only for single\n",
    "    # shot recognition like command or query.\n",
    "    # For long-running multi-utterance recognition, use start_continuous_recognition() instead.\n",
    "    result = speech_recognizer.recognize_once()\n",
    "\n",
    "    # Check the result\n",
    "    if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "        print(\"Recognized: {}\".format(result.text))\n",
    "    elif result.reason == speechsdk.ResultReason.NoMatch:\n",
    "        print(\"No speech could be recognized: {}\".format(result.no_match_details))\n",
    "    elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = result.cancellation_details\n",
    "        print(\"Speech Recognition canceled: {}\".format(cancellation_details.reason))\n",
    "        if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "    # </SpeechRecognitionWithCompressedFile>\n",
    "\n",
    "\n",
    "def speech_recognize_once_from_file_with_customized_model():\n",
    "    \"\"\"performs one-shot speech recognition with input from an audio file, specifying a custom\n",
    "    model\"\"\"\n",
    "    # <SpeechRecognitionUsingCustomizedModel>\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "\n",
    "    # Create source language configuration with the speech language and the endpoint ID of your customized model\n",
    "    # Replace with your speech language and CRIS endpoint ID.\n",
    "    source_language_config = speechsdk.languageconfig.SourceLanguageConfig(\"zh-CN\", \"YourEndpointId\")\n",
    "\n",
    "    audio_config = speechsdk.audio.AudioConfig(filename=weatherfilename)\n",
    "    # Creates a speech recognizer using a file as audio input and specify the source language config\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(\n",
    "        speech_config=speech_config, source_language_config=source_language_config, audio_config=audio_config)\n",
    "\n",
    "    # Starts speech recognition, and returns after a single utterance is recognized. The end of a\n",
    "    # single utterance is determined by listening for silence at the end or until a maximum of 15\n",
    "    # seconds of audio is processed. It returns the recognition text as result.\n",
    "    # Note: Since recognize_once() returns only a single utterance, it is suitable only for single\n",
    "    # shot recognition like command or query.\n",
    "    # For long-running multi-utterance recognition, use start_continuous_recognition() instead.\n",
    "    result = speech_recognizer.recognize_once()\n",
    "\n",
    "    # Check the result\n",
    "    if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "        print(\"Recognized: {}\".format(result.text))\n",
    "    elif result.reason == speechsdk.ResultReason.NoMatch:\n",
    "        print(\"No speech could be recognized: {}\".format(result.no_match_details))\n",
    "    elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = result.cancellation_details\n",
    "        print(\"Speech Recognition canceled: {}\".format(cancellation_details.reason))\n",
    "        if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "    # </SpeechRecognitionUsingCustomizedModel>\n",
    "\n",
    "\n",
    "def speech_recognize_once_from_file_with_custom_endpoint_parameters():\n",
    "    \"\"\"performs one-shot speech recognition with input from an audio file, specifying an\n",
    "    endpoint with custom parameters\"\"\"\n",
    "    initial_silence_timeout_ms = 15 * 1e3\n",
    "    template = \"wss://{}.stt.speech.microsoft.com/speech/recognition\" \\\n",
    "        \"/conversation/cognitiveservices/v1?initialSilenceTimeoutMs={:d}\"\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key,\n",
    "                                           endpoint=template.format(service_region, int(initial_silence_timeout_ms)))\n",
    "    print(\"Using endpoint\", speech_config.get_property(speechsdk.PropertyId.SpeechServiceConnection_Endpoint))\n",
    "    audio_config = speechsdk.audio.AudioConfig(filename=weatherfilename)\n",
    "    # Creates a speech recognizer using a file as audio input.\n",
    "    # The default language is \"en-us\".\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "    # Starts speech recognition, and returns after a single utterance is recognized. The end of a\n",
    "    # single utterance is determined by listening for silence at the end or until a maximum of 15\n",
    "    # seconds of audio is processed. It returns the recognition text as result.\n",
    "    # Note: Since recognize_once() returns only a single utterance, it is suitable only for single\n",
    "    # shot recognition like command or query.\n",
    "    # For long-running multi-utterance recognition, use start_continuous_recognition() instead.\n",
    "    result = speech_recognizer.recognize_once()\n",
    "\n",
    "    # Check the result\n",
    "    if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "        print(\"Recognized: {}\".format(result.text))\n",
    "    elif result.reason == speechsdk.ResultReason.NoMatch:\n",
    "        print(\"No speech could be recognized: {}\".format(result.no_match_details))\n",
    "    elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = result.cancellation_details\n",
    "        print(\"Speech Recognition canceled: {}\".format(cancellation_details.reason))\n",
    "        if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "\n",
    "\n",
    "def speech_recognize_async_from_file(in_key, in_region, in_file, in_lang):\n",
    "    \"\"\"performs one-shot speech recognition asynchronously with input from an audio file\"\"\"\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=in_key, region=in_region)\n",
    "    audio_config = speechsdk.audio.AudioConfig(filename=in_file)\n",
    "    # Creates a speech recognizer using a file as audio input.\n",
    "    # The default language is \"en-us\".\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config, language=in_lang)\n",
    "\n",
    "    # Perform recognition. `recognize_async` does not block until recognition is complete,\n",
    "    # so other tasks can be performed while recognition is running.\n",
    "    # However, recognition stops when the first utterance has been recognized.\n",
    "    # For long-running recognition, use continuous recognitions instead.\n",
    "    result_future = speech_recognizer.recognize_once_async()\n",
    "\n",
    "    print('recognition is running....')\n",
    "    # Other tasks can be performed here...\n",
    "\n",
    "    # Retrieve the recognition result. This blocks until recognition is complete.\n",
    "    result = result_future.get()\n",
    "\n",
    "    # Check the result\n",
    "    if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "        print(\"Recognized: {}\".format(result.text))\n",
    "    elif result.reason == speechsdk.ResultReason.NoMatch:\n",
    "        print(\"No speech could be recognized: {}\".format(result.no_match_details))\n",
    "    elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = result.cancellation_details\n",
    "        print(\"Speech Recognition canceled: {}\".format(cancellation_details.reason))\n",
    "        if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "\n",
    "\n",
    "def speech_recognize_continuous_from_file():\n",
    "    \"\"\"performs continuous speech recognition with input from an audio file\"\"\"\n",
    "    # <SpeechContinuousRecognitionWithFile>\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "    audio_config = speechsdk.audio.AudioConfig(filename=weatherfilename)\n",
    "\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "    done = False\n",
    "\n",
    "    def stop_cb(evt: speechsdk.SessionEventArgs):\n",
    "        \"\"\"callback that signals to stop continuous recognition upon receiving an event `evt`\"\"\"\n",
    "        print('CLOSING on {}'.format(evt))\n",
    "        nonlocal done\n",
    "        done = True\n",
    "\n",
    "    # Connect callbacks to the events fired by the speech recognizer\n",
    "    speech_recognizer.recognizing.connect(lambda evt: print('RECOGNIZING: {}'.format(evt)))\n",
    "    speech_recognizer.recognized.connect(lambda evt: print('RECOGNIZED: {}'.format(evt)))\n",
    "    speech_recognizer.session_started.connect(lambda evt: print('SESSION STARTED: {}'.format(evt)))\n",
    "    speech_recognizer.session_stopped.connect(lambda evt: print('SESSION STOPPED {}'.format(evt)))\n",
    "    speech_recognizer.canceled.connect(lambda evt: print('CANCELED {}'.format(evt)))\n",
    "    # Stop continuous recognition on either session stopped or canceled events\n",
    "    speech_recognizer.session_stopped.connect(stop_cb)\n",
    "    speech_recognizer.canceled.connect(stop_cb)\n",
    "\n",
    "    # Start continuous speech recognition\n",
    "    speech_recognizer.start_continuous_recognition()\n",
    "    while not done:\n",
    "        time.sleep(.5)\n",
    "\n",
    "    speech_recognizer.stop_continuous_recognition()\n",
    "    # </SpeechContinuousRecognitionWithFile>\n",
    "\n",
    "\n",
    "def speech_recognize_continuous_async_from_microphone():\n",
    "    \"\"\"performs continuous speech recognition asynchronously with input from microphone\"\"\"\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "    # The default language is \"en-us\".\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config)\n",
    "\n",
    "    done = False\n",
    "\n",
    "    def recognizing_cb(evt: speechsdk.SpeechRecognitionEventArgs):\n",
    "        print('RECOGNIZING: {}'.format(evt))\n",
    "\n",
    "    def recognized_cb(evt: speechsdk.SpeechRecognitionEventArgs):\n",
    "        print('RECOGNIZED: {}'.format(evt))\n",
    "\n",
    "    def stop_cb(evt: speechsdk.SessionEventArgs):\n",
    "        \"\"\"callback that signals to stop continuous recognition\"\"\"\n",
    "        print('CLOSING on {}'.format(evt))\n",
    "        nonlocal done\n",
    "        done = True\n",
    "\n",
    "    # Connect callbacks to the events fired by the speech recognizer\n",
    "    speech_recognizer.recognizing.connect(recognizing_cb)\n",
    "    speech_recognizer.recognized.connect(recognized_cb)\n",
    "    speech_recognizer.session_stopped.connect(stop_cb)\n",
    "    speech_recognizer.canceled.connect(stop_cb)\n",
    "\n",
    "    # Perform recognition. `start_continuous_recognition_async asynchronously initiates continuous recognition operation,\n",
    "    # Other tasks can be performed on this thread while recognition starts...\n",
    "    # wait on result_future.get() to know when initialization is done.\n",
    "    # Call stop_continuous_recognition_async() to stop recognition.\n",
    "    result_future = speech_recognizer.start_continuous_recognition_async()\n",
    "\n",
    "    result_future.get()  # wait for voidfuture, so we know engine initialization is done.\n",
    "    print('Continuous Recognition is now running, say something.')\n",
    "\n",
    "    while not done:\n",
    "        # No real sample parallel work to do on this thread, so just wait for user to type stop.\n",
    "        # Can't exit function or speech_recognizer will go out of scope and be destroyed while running.\n",
    "        print('type \"stop\" then enter when done')\n",
    "        stop = input()\n",
    "        if (stop.lower() == \"stop\"):\n",
    "            print('Stopping async recognition.')\n",
    "            speech_recognizer.stop_continuous_recognition_async()\n",
    "            break\n",
    "\n",
    "    print(\"recognition stopped, main thread can exit now.\")\n",
    "\n",
    "\n",
    "# <SpeechRecognitionUsingKeywordModel>\n",
    "def speech_recognize_keyword_from_microphone():\n",
    "    \"\"\"performs keyword-triggered speech recognition with input microphone\"\"\"\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "\n",
    "    # Creates an instance of a keyword recognition model. Update this to\n",
    "    # point to the location of your keyword recognition model.\n",
    "    model = speechsdk.KeywordRecognitionModel(\"YourKeywordRecognitionModelFile.table\")\n",
    "\n",
    "    # The phrase your keyword recognition model triggers on.\n",
    "    keyword = \"YourKeyword\"\n",
    "\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config)\n",
    "\n",
    "    done = False\n",
    "\n",
    "    def stop_cb(evt: speechsdk.SessionEventArgs):\n",
    "        \"\"\"callback that signals to stop continuous recognition upon receiving an event `evt`\"\"\"\n",
    "        print('CLOSING on {}'.format(evt))\n",
    "        nonlocal done\n",
    "        done = True\n",
    "\n",
    "    def recognizing_cb(evt: speechsdk.SpeechRecognitionEventArgs):\n",
    "        \"\"\"callback for recognizing event\"\"\"\n",
    "        if evt.result.reason == speechsdk.ResultReason.RecognizingKeyword:\n",
    "            print('RECOGNIZING KEYWORD: {}'.format(evt))\n",
    "        elif evt.result.reason == speechsdk.ResultReason.RecognizingSpeech:\n",
    "            print('RECOGNIZING: {}'.format(evt))\n",
    "\n",
    "    def recognized_cb(evt: speechsdk.SpeechRecognitionEventArgs):\n",
    "        \"\"\"callback for recognized event\"\"\"\n",
    "        if evt.result.reason == speechsdk.ResultReason.RecognizedKeyword:\n",
    "            print('RECOGNIZED KEYWORD: {}'.format(evt))\n",
    "        elif evt.result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "            print('RECOGNIZED: {}'.format(evt))\n",
    "        elif evt.result.reason == speechsdk.ResultReason.NoMatch:\n",
    "            print('NOMATCH: {}'.format(evt))\n",
    "\n",
    "    # Connect callbacks to the events fired by the speech recognizer\n",
    "    speech_recognizer.recognizing.connect(recognizing_cb)\n",
    "    speech_recognizer.recognized.connect(recognized_cb)\n",
    "    speech_recognizer.session_started.connect(lambda evt: print('SESSION STARTED: {}'.format(evt)))\n",
    "    speech_recognizer.session_stopped.connect(lambda evt: print('SESSION STOPPED {}'.format(evt)))\n",
    "    speech_recognizer.canceled.connect(lambda evt: print('CANCELED {}'.format(evt)))\n",
    "    # Stop continuous recognition on either session stopped or canceled events\n",
    "    speech_recognizer.session_stopped.connect(stop_cb)\n",
    "    speech_recognizer.canceled.connect(stop_cb)\n",
    "\n",
    "    # Start keyword recognition\n",
    "    speech_recognizer.start_keyword_recognition(model)\n",
    "    print('Say something starting with \"{}\" followed by whatever you want...'.format(keyword))\n",
    "    while not done:\n",
    "        time.sleep(.5)\n",
    "\n",
    "    speech_recognizer.stop_keyword_recognition()\n",
    "# </SpeechRecognitionUsingKeywordModel>\n",
    "\n",
    "\n",
    "def speech_recognition_with_pull_stream():\n",
    "    \"\"\"gives an example how to use a pull audio stream to recognize speech from a custom audio\n",
    "    source\"\"\"\n",
    "    class WavFileReaderCallback(speechsdk.audio.PullAudioInputStreamCallback):\n",
    "        \"\"\"Example class that implements the Pull Audio Stream interface to recognize speech from\n",
    "        an audio file\"\"\"\n",
    "        def __init__(self, filename: str):\n",
    "            super().__init__()\n",
    "            self._file_h = wave.open(filename, mode=None)\n",
    "\n",
    "            self.sample_width = self._file_h.getsampwidth()\n",
    "\n",
    "            assert self._file_h.getnchannels() == 1\n",
    "            assert self._file_h.getsampwidth() == 2\n",
    "            assert self._file_h.getframerate() == 16000\n",
    "            assert self._file_h.getcomptype() == 'NONE'\n",
    "\n",
    "        def read(self, buffer: memoryview) -> int:\n",
    "            \"\"\"read callback function\"\"\"\n",
    "            size = buffer.nbytes\n",
    "            frames = self._file_h.readframes(size // self.sample_width)\n",
    "\n",
    "            buffer[:len(frames)] = frames\n",
    "\n",
    "            return len(frames)\n",
    "\n",
    "        def close(self):\n",
    "            \"\"\"close callback function\"\"\"\n",
    "            self._file_h.close()\n",
    "\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "\n",
    "    # Specify the audio format\n",
    "    wave_format = speechsdk.audio.AudioStreamFormat(samples_per_second=16000, bits_per_sample=16,\n",
    "                                                    channels=1)\n",
    "\n",
    "    # Setup the audio stream\n",
    "    callback = WavFileReaderCallback(weatherfilename)\n",
    "    stream = speechsdk.audio.PullAudioInputStream(callback, wave_format)\n",
    "    audio_config = speechsdk.audio.AudioConfig(stream=stream)\n",
    "\n",
    "    # Instantiate the speech recognizer with pull stream input\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "    done = False\n",
    "\n",
    "    def stop_cb(evt: speechsdk.SessionEventArgs):\n",
    "        \"\"\"callback that signals to stop continuous recognition upon receiving an event `evt`\"\"\"\n",
    "        print('CLOSING on {}'.format(evt))\n",
    "        nonlocal done\n",
    "        done = True\n",
    "\n",
    "    # Connect callbacks to the events fired by the speech recognizer\n",
    "    speech_recognizer.recognizing.connect(lambda evt: print('RECOGNIZING: {}'.format(evt)))\n",
    "    speech_recognizer.recognized.connect(lambda evt: print('RECOGNIZED: {}'.format(evt)))\n",
    "    speech_recognizer.session_started.connect(lambda evt: print('SESSION STARTED: {}'.format(evt)))\n",
    "    speech_recognizer.session_stopped.connect(lambda evt: print('SESSION STOPPED {}'.format(evt)))\n",
    "    speech_recognizer.canceled.connect(lambda evt: print('CANCELED {}'.format(evt)))\n",
    "    # Stop continuous recognition on either session stopped or canceled events\n",
    "    speech_recognizer.session_stopped.connect(stop_cb)\n",
    "    speech_recognizer.canceled.connect(stop_cb)\n",
    "\n",
    "    # Start continuous speech recognition\n",
    "    speech_recognizer.start_continuous_recognition()\n",
    "\n",
    "    while not done:\n",
    "        time.sleep(.5)\n",
    "\n",
    "    speech_recognizer.stop_continuous_recognition()\n",
    "\n",
    "\n",
    "def read_wave_header(file_path):\n",
    "    with wave.open(file_path, 'rb') as audio_file:\n",
    "        framerate = audio_file.getframerate()\n",
    "        bits_per_sample = audio_file.getsampwidth() * 8\n",
    "        num_channels = audio_file.getnchannels()\n",
    "        return framerate, bits_per_sample, num_channels\n",
    "\n",
    "\n",
    "def push_stream_writer(stream):\n",
    "    # The number of bytes to push per buffer\n",
    "    n_bytes = 3200\n",
    "    wav_fh = wave.open(weatherfilename)\n",
    "    # Start pushing data until all data has been read from the file\n",
    "    try:\n",
    "        while True:\n",
    "            frames = wav_fh.readframes(n_bytes // 2)\n",
    "            print('read {} bytes'.format(len(frames)))\n",
    "            if not frames:\n",
    "                break\n",
    "            stream.write(frames)\n",
    "            time.sleep(.1)\n",
    "    finally:\n",
    "        wav_fh.close()\n",
    "        stream.close()  # must be done to signal the end of stream\n",
    "\n",
    "\n",
    "def speech_recognition_with_push_stream():\n",
    "    \"\"\"gives an example how to use a push audio stream to recognize speech from a custom audio\n",
    "    source\"\"\"\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "\n",
    "    # Setup the audio stream\n",
    "    stream = speechsdk.audio.PushAudioInputStream()\n",
    "    audio_config = speechsdk.audio.AudioConfig(stream=stream)\n",
    "\n",
    "    # Instantiate the speech recognizer with push stream input\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "    recognition_done = threading.Event()\n",
    "\n",
    "    # Connect callbacks to the events fired by the speech recognizer\n",
    "    def session_stopped_cb(evt):\n",
    "        \"\"\"callback that signals to stop continuous recognition upon receiving an event `evt`\"\"\"\n",
    "        print('SESSION STOPPED: {}'.format(evt))\n",
    "        recognition_done.set()\n",
    "\n",
    "    speech_recognizer.recognizing.connect(lambda evt: print('RECOGNIZING: {}'.format(evt)))\n",
    "    speech_recognizer.recognized.connect(lambda evt: print('RECOGNIZED: {}'.format(evt)))\n",
    "    speech_recognizer.session_started.connect(lambda evt: print('SESSION STARTED: {}'.format(evt)))\n",
    "    speech_recognizer.session_stopped.connect(session_stopped_cb)\n",
    "    speech_recognizer.canceled.connect(lambda evt: print('CANCELED {}'.format(evt)))\n",
    "\n",
    "    # Start push stream writer thread\n",
    "    push_stream_writer_thread = threading.Thread(target=push_stream_writer, args=[stream])\n",
    "    push_stream_writer_thread.start()\n",
    "\n",
    "    # Start continuous speech recognition\n",
    "    speech_recognizer.start_continuous_recognition()\n",
    "\n",
    "    # Wait until all input processed\n",
    "    recognition_done.wait()\n",
    "\n",
    "    # Stop recognition and clean up\n",
    "    speech_recognizer.stop_continuous_recognition()\n",
    "    push_stream_writer_thread.join()\n",
    "\n",
    "\n",
    "def speech_recognition_with_push_stream_mulaw():\n",
    "    \"\"\"gives an example how to use a push mulaw audio stream to recognize speech from a custom audio\n",
    "    source\"\"\"\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "\n",
    "    # Setup the audio stream\n",
    "    audio_format = speechsdk.audio.AudioStreamFormat(samples_per_second=16000,\n",
    "                                                     bits_per_sample=8,\n",
    "                                                     channels=1,\n",
    "                                                     wave_stream_format=speechsdk.AudioStreamWaveFormat.MULAW)\n",
    "    stream = speechsdk.audio.PushAudioInputStream(stream_format=audio_format)\n",
    "    audio_config = speechsdk.audio.AudioConfig(stream=stream)\n",
    "\n",
    "    # Instantiate the speech recognizer with push stream input\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "    recognition_done = threading.Event()\n",
    "\n",
    "    # Connect callbacks to the events fired by the speech recognizer\n",
    "    def session_stopped_cb(evt):\n",
    "        \"\"\"callback that signals to stop continuous recognition upon receiving an event `evt`\"\"\"\n",
    "        print('SESSION STOPPED: {}'.format(evt))\n",
    "        recognition_done.set()\n",
    "\n",
    "    speech_recognizer.recognizing.connect(lambda evt: print('RECOGNIZING: {}'.format(evt)))\n",
    "    speech_recognizer.recognized.connect(lambda evt: print('RECOGNIZED: {}'.format(evt)))\n",
    "    speech_recognizer.session_started.connect(lambda evt: print('SESSION STARTED: {}'.format(evt)))\n",
    "    speech_recognizer.session_stopped.connect(session_stopped_cb)\n",
    "    speech_recognizer.canceled.connect(lambda evt: print('CANCELED {}'.format(evt)))\n",
    "\n",
    "    # Start continuous speech recognition\n",
    "    speech_recognizer.start_continuous_recognition()\n",
    "\n",
    "    # Open the wav file and push it to the push stream.\n",
    "    # NOTE the wav header must be skipped before pushing the data to the stream.\n",
    "    with open(weatherfilenamemulaw, 'rb') as audio_file:\n",
    "        wav_header_size = utils.get_wav_header_size(weatherfilenamemulaw)\n",
    "        # Read the wave header\n",
    "        header = audio_file.read(wav_header_size)  # noqa: F841 # pylint: disable=unused-variable\n",
    "        # Read the audio data\n",
    "        audio_data = audio_file.read()\n",
    "        stream.write(audio_data)\n",
    "        stream.close()\n",
    "\n",
    "    # Wait until all input processed\n",
    "    recognition_done.wait()\n",
    "\n",
    "    # Stop recognition and clean up\n",
    "    speech_recognizer.stop_continuous_recognition()\n",
    "\n",
    "\n",
    "def speech_recognize_once_with_auto_language_detection_from_mic():\n",
    "    \"\"\"performs one-shot speech recognition from the default microphone with auto language detection\"\"\"\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "\n",
    "    # Create the auto detection language configuration with the potential source language candidates\n",
    "    auto_detect_source_language_config = \\\n",
    "        speechsdk.languageconfig.AutoDetectSourceLanguageConfig(languages=[\"de-DE\", \"en-US\"])\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(\n",
    "        speech_config=speech_config, auto_detect_source_language_config=auto_detect_source_language_config)\n",
    "    result = speech_recognizer.recognize_once()\n",
    "\n",
    "    # Check the result\n",
    "    if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "        auto_detect_source_language_result = speechsdk.AutoDetectSourceLanguageResult(result)\n",
    "        print(\"Recognized: {} in language {}\".format(result.text, auto_detect_source_language_result.language))\n",
    "    elif result.reason == speechsdk.ResultReason.NoMatch:\n",
    "        print(\"No speech could be recognized\")\n",
    "    elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = result.cancellation_details\n",
    "        print(\"Speech Recognition canceled: {}\".format(cancellation_details.reason))\n",
    "        if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "\n",
    "\n",
    "def speech_recognize_with_auto_language_detection_UsingCustomizedModel():\n",
    "    \"\"\"performs speech recognition from the audio file with auto language detection, using customized model\"\"\"\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "    audio_config = speechsdk.audio.AudioConfig(filename=weatherfilename)\n",
    "\n",
    "    # Replace the languages with your languages in BCP-47 format, e.g. fr-FR.\n",
    "    # Please see https://docs.microsoft.com/azure/cognitive-services/speech-service/language-support\n",
    "    # for all supported languages\n",
    "    en_language_config = speechsdk.languageconfig.SourceLanguageConfig(\"en-US\")\n",
    "    # Replace the languages with your languages in BCP-47 format, e.g. zh-CN.\n",
    "    # Set the endpoint ID of your customized mode that will be used for fr-FR.\n",
    "    # Replace with your own CRIS endpoint ID.\n",
    "    fr_language_config = speechsdk.languageconfig.SourceLanguageConfig(\"fr-FR\", \"myendpointId\")\n",
    "    # Create the auto detection language configuration with the source language configurations\n",
    "    auto_detect_source_language_config = speechsdk.languageconfig.AutoDetectSourceLanguageConfig(\n",
    "        sourceLanguageConfigs=[en_language_config, fr_language_config])\n",
    "\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(\n",
    "        speech_config=speech_config,\n",
    "        auto_detect_source_language_config=auto_detect_source_language_config,\n",
    "        audio_config=audio_config)\n",
    "    result = speech_recognizer.recognize_once()\n",
    "\n",
    "    # Check the result\n",
    "    if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "        auto_detect_source_language_result = speechsdk.AutoDetectSourceLanguageResult(result)\n",
    "        print(\"Recognized: {} in language {}\".format(result.text, auto_detect_source_language_result.language))\n",
    "    elif result.reason == speechsdk.ResultReason.NoMatch:\n",
    "        print(\"No speech could be recognized\")\n",
    "    elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = result.cancellation_details\n",
    "        print(\"Speech Recognition canceled: {}\".format(cancellation_details.reason))\n",
    "        if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "\n",
    "\n",
    "def speech_recognize_keyword_locally_from_microphone():\n",
    "    \"\"\"runs keyword spotting locally, with direct access to the result audio\"\"\"\n",
    "\n",
    "    # Creates an instance of a keyword recognition model. Update this to\n",
    "    # point to the location of your keyword recognition model.\n",
    "    model = speechsdk.KeywordRecognitionModel(\"YourKeywordRecognitionModelFile.table\")\n",
    "\n",
    "    # The phrase your keyword recognition model triggers on.\n",
    "    keyword = \"YourKeyword\"\n",
    "\n",
    "    # Create a local keyword recognizer with the default microphone device for input.\n",
    "    keyword_recognizer = speechsdk.KeywordRecognizer()\n",
    "\n",
    "    done = False\n",
    "\n",
    "    def recognized_cb(evt: speechsdk.SpeechRecognitionEventArgs):\n",
    "        # Only a keyword phrase is recognized. The result cannot be 'NoMatch'\n",
    "        # and there is no timeout. The recognizer runs until a keyword phrase\n",
    "        # is detected or recognition is canceled (by stop_recognition_async()\n",
    "        # or due to the end of an input file or stream).\n",
    "        result = evt.result\n",
    "        if result.reason == speechsdk.ResultReason.RecognizedKeyword:\n",
    "            print(\"RECOGNIZED KEYWORD: {}\".format(result.text))\n",
    "        nonlocal done\n",
    "        done = True\n",
    "\n",
    "    def canceled_cb(evt: speechsdk.SpeechRecognitionCanceledEventArgs):\n",
    "        result = evt.result\n",
    "        if result.reason == speechsdk.ResultReason.Canceled:\n",
    "            print('CANCELED: {}'.format(result.cancellation_details.reason))\n",
    "        nonlocal done\n",
    "        done = True\n",
    "\n",
    "    # Connect callbacks to the events fired by the keyword recognizer.\n",
    "    keyword_recognizer.recognized.connect(recognized_cb)\n",
    "    keyword_recognizer.canceled.connect(canceled_cb)\n",
    "\n",
    "    # Start keyword recognition.\n",
    "    result_future = keyword_recognizer.recognize_once_async(model)\n",
    "    print('Say something starting with \"{}\" followed by whatever you want...'.format(keyword))\n",
    "    result = result_future.get()\n",
    "\n",
    "    # Read result audio (incl. the keyword).\n",
    "    if result.reason == speechsdk.ResultReason.RecognizedKeyword:\n",
    "        time.sleep(2)  # give some time so the stream is filled\n",
    "        result_stream = speechsdk.AudioDataStream(result)\n",
    "        result_stream.detach_input()  # stop any more data from input getting to the stream\n",
    "\n",
    "        save_future = result_stream.save_to_wav_file_async(\"AudioFromRecognizedKeyword.wav\")\n",
    "        print('Saving file...')\n",
    "        save_future.get()\n",
    "\n",
    "    # If active keyword recognition needs to be stopped before results, it can be done with\n",
    "    #\n",
    "    #   stop_future = keyword_recognizer.stop_recognition_async()\n",
    "    #   print('Stopping...')\n",
    "    #   stopped = stop_future.get()\n",
    "\n",
    "\n",
    "def pronunciation_assessment_from_microphone():\n",
    "    \"\"\"Performs one-shot pronunciation assessment asynchronously with input from microphone.\n",
    "        See more information at https://aka.ms/csspeech/pa\"\"\"\n",
    "\n",
    "    # Creates an instance of a speech config with specified subscription key and service region.\n",
    "    # Replace with your own subscription key and service region (e.g., \"westus\").\n",
    "    config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "\n",
    "    # The pronunciation assessment service has a longer default end silence timeout (5 seconds) than normal STT\n",
    "    # as the pronunciation assessment is widely used in education scenario where kids have longer break in reading.\n",
    "    # You can adjust the end silence timeout based on your real scenario.\n",
    "    config.set_property(speechsdk.PropertyId.SpeechServiceConnection_EndSilenceTimeoutMs, \"3000\")\n",
    "\n",
    "    reference_text = \"\"\n",
    "    pronunciation_config = speechsdk.PronunciationAssessmentConfig(\n",
    "        reference_text=reference_text,\n",
    "        grading_system=speechsdk.PronunciationAssessmentGradingSystem.HundredMark,\n",
    "        granularity=speechsdk.PronunciationAssessmentGranularity.Phoneme,\n",
    "        enable_miscue=True)\n",
    "    pronunciation_config.enable_prosody_assessment()\n",
    "\n",
    "    # Create a speech recognizer, also specify the speech language\n",
    "    recognizer = speechsdk.SpeechRecognizer(speech_config=config, language=\"en-US\")\n",
    "    while True:\n",
    "        # Receives reference text from console input.\n",
    "        print('Enter reference text you want to assess, or enter empty text to exit.')\n",
    "        print('> ', end='')\n",
    "\n",
    "        try:\n",
    "            reference_text = input()\n",
    "        except EOFError:\n",
    "            break\n",
    "\n",
    "        if not reference_text:\n",
    "            break\n",
    "\n",
    "        pronunciation_config.reference_text = reference_text\n",
    "        pronunciation_config.apply_to(recognizer)\n",
    "\n",
    "        # Starts recognizing.\n",
    "        print('Read out \"{}\" for pronunciation assessment ...'.format(reference_text))\n",
    "\n",
    "        # Note: Since recognize_once() returns only a single utterance, it is suitable only for single\n",
    "        # shot evaluation.\n",
    "        # For long-running multi-utterance pronunciation evaluation, use start_continuous_recognition() instead.\n",
    "        result = recognizer.recognize_once_async().get()\n",
    "\n",
    "        # Check the result\n",
    "        if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "            print('Recognized: {}'.format(result.text))\n",
    "            print('  Pronunciation Assessment Result:')\n",
    "\n",
    "            pronunciation_result = speechsdk.PronunciationAssessmentResult(result)\n",
    "            print('    Accuracy score: {}, Prosody score: {}, Pronunciation score: {}, Completeness score : {}, FluencyScore: {}'.format(\n",
    "                pronunciation_result.accuracy_score, pronunciation_result.prosody_score, pronunciation_result.pronunciation_score,\n",
    "                pronunciation_result.completeness_score, pronunciation_result.fluency_score\n",
    "            ))\n",
    "            print('  Word-level details:')\n",
    "            for idx, word in enumerate(pronunciation_result.words):\n",
    "                print('    {}: word: {}, accuracy score: {}, error type: {};'.format(\n",
    "                    idx + 1, word.word, word.accuracy_score, word.error_type\n",
    "                ))\n",
    "        elif result.reason == speechsdk.ResultReason.NoMatch:\n",
    "            print(\"No speech could be recognized\")\n",
    "        elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "            cancellation_details = result.cancellation_details\n",
    "            print(\"Speech Recognition canceled: {}\".format(cancellation_details.reason))\n",
    "            if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "                print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "\n",
    "\n",
    "def pronunciation_assessment_continuous_from_file():\n",
    "    \"\"\"Performs continuous pronunciation assessment asynchronously with input from an audio file.\n",
    "        See more information at https://aka.ms/csspeech/pa\"\"\"\n",
    "\n",
    "    import difflib\n",
    "    import json\n",
    "\n",
    "    # Creates an instance of a speech config with specified subscription key and service region.\n",
    "    # Replace with your own subscription key and service region (e.g., \"westus\").\n",
    "    # Note: The sample is for en-US language.\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "    audio_config = speechsdk.audio.AudioConfig(filename=weatherfilename)\n",
    "\n",
    "    reference_text = \"What's the weather like?\"\n",
    "    # Create pronunciation assessment config, set grading system, granularity and if enable miscue based on your requirement.\n",
    "    enable_miscue = True\n",
    "    enable_prosody_assessment = True\n",
    "    pronunciation_config = speechsdk.PronunciationAssessmentConfig(\n",
    "        reference_text=reference_text,\n",
    "        grading_system=speechsdk.PronunciationAssessmentGradingSystem.HundredMark,\n",
    "        granularity=speechsdk.PronunciationAssessmentGranularity.Phoneme,\n",
    "        enable_miscue=enable_miscue)\n",
    "    if enable_prosody_assessment:\n",
    "        pronunciation_config.enable_prosody_assessment()\n",
    "\n",
    "    # Creates a speech recognizer using a file as audio input.\n",
    "    language = 'en-US'\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, language=language, audio_config=audio_config)\n",
    "    # Apply pronunciation assessment config to speech recognizer\n",
    "    pronunciation_config.apply_to(speech_recognizer)\n",
    "\n",
    "    done = False\n",
    "    recognized_words = []\n",
    "    prosody_scores = []\n",
    "    fluency_scores = []\n",
    "    durations = []\n",
    "\n",
    "    def stop_cb(evt: speechsdk.SessionEventArgs):\n",
    "        \"\"\"callback that signals to stop continuous recognition upon receiving an event `evt`\"\"\"\n",
    "        print('CLOSING on {}'.format(evt))\n",
    "        nonlocal done\n",
    "        done = True\n",
    "\n",
    "    def recognized(evt: speechsdk.SpeechRecognitionEventArgs):\n",
    "        print(\"pronunciation assessment for: {}\".format(evt.result.text))\n",
    "        pronunciation_result = speechsdk.PronunciationAssessmentResult(evt.result)\n",
    "        print(\"    Accuracy score: {}, prosody score: {}, pronunciation score: {}, completeness score : {}, fluency score: {}\".format(\n",
    "            pronunciation_result.accuracy_score, pronunciation_result.prosody_score, pronunciation_result.pronunciation_score,\n",
    "            pronunciation_result.completeness_score, pronunciation_result.fluency_score\n",
    "        ))\n",
    "        nonlocal recognized_words, prosody_scores, fluency_scores, durations\n",
    "        recognized_words += pronunciation_result.words\n",
    "        fluency_scores.append(pronunciation_result.fluency_score)\n",
    "        if pronunciation_result.prosody_score is not None:\n",
    "            prosody_scores.append(pronunciation_result.prosody_score)\n",
    "        json_result = evt.result.properties.get(speechsdk.PropertyId.SpeechServiceResponse_JsonResult)\n",
    "        jo = json.loads(json_result)\n",
    "        nb = jo[\"NBest\"][0]\n",
    "        durations.append(sum([int(w[\"Duration\"]) for w in nb[\"Words\"]]))\n",
    "\n",
    "    # Connect callbacks to the events fired by the speech recognizer\n",
    "    speech_recognizer.recognized.connect(recognized)\n",
    "    speech_recognizer.session_started.connect(lambda evt: print('SESSION STARTED: {}'.format(evt)))\n",
    "    speech_recognizer.session_stopped.connect(lambda evt: print('SESSION STOPPED {}'.format(evt)))\n",
    "    speech_recognizer.canceled.connect(lambda evt: print('CANCELED {}'.format(evt)))\n",
    "    # Stop continuous recognition on either session stopped or canceled events\n",
    "    speech_recognizer.session_stopped.connect(stop_cb)\n",
    "    speech_recognizer.canceled.connect(stop_cb)\n",
    "\n",
    "    # Start continuous pronunciation assessment\n",
    "    speech_recognizer.start_continuous_recognition()\n",
    "    while not done:\n",
    "        time.sleep(.5)\n",
    "\n",
    "    speech_recognizer.stop_continuous_recognition()\n",
    "\n",
    "    # We need to convert the reference text to lower case, and split to words, then remove the punctuations.\n",
    "    if language == 'zh-CN':\n",
    "        # Use jieba package to split words for Chinese\n",
    "        import jieba\n",
    "        import zhon.hanzi\n",
    "        jieba.suggest_freq([x.word for x in recognized_words], True)\n",
    "        reference_words = [w for w in jieba.cut(reference_text) if w not in zhon.hanzi.punctuation]\n",
    "    else:\n",
    "        reference_words = [w.strip(string.punctuation) for w in reference_text.lower().split()]\n",
    "\n",
    "    # For continuous pronunciation assessment mode, the service won't return the words with `Insertion` or `Omission`\n",
    "    # even if miscue is enabled.\n",
    "    # We need to compare with the reference text after received all recognized words to get these error words.\n",
    "    if enable_miscue:\n",
    "        diff = difflib.SequenceMatcher(None, reference_words, [x.word.lower() for x in recognized_words])\n",
    "        final_words = []\n",
    "        for tag, i1, i2, j1, j2 in diff.get_opcodes():\n",
    "            if tag in ['insert', 'replace']:\n",
    "                for word in recognized_words[j1:j2]:\n",
    "                    if word.error_type == 'None':\n",
    "                        word._error_type = 'Insertion'\n",
    "                    final_words.append(word)\n",
    "            if tag in ['delete', 'replace']:\n",
    "                for word_text in reference_words[i1:i2]:\n",
    "                    word = speechsdk.PronunciationAssessmentWordResult({\n",
    "                        'Word': word_text,\n",
    "                        'PronunciationAssessment': {\n",
    "                            'ErrorType': 'Omission',\n",
    "                        }\n",
    "                    })\n",
    "                    final_words.append(word)\n",
    "            if tag == 'equal':\n",
    "                final_words += recognized_words[j1:j2]\n",
    "    else:\n",
    "        final_words = recognized_words\n",
    "\n",
    "    # We can calculate whole accuracy by averaging\n",
    "    final_accuracy_scores = []\n",
    "    for word in final_words:\n",
    "        if word.error_type == 'Insertion':\n",
    "            continue\n",
    "        else:\n",
    "            final_accuracy_scores.append(word.accuracy_score)\n",
    "    accuracy_score = sum(final_accuracy_scores) / len(final_accuracy_scores)\n",
    "    # Re-calculate the prosody score by averaging\n",
    "    if len(prosody_scores) == 0:\n",
    "        prosody_score = float(\"nan\")\n",
    "    else:\n",
    "        prosody_score = sum(prosody_scores) / len(prosody_scores)\n",
    "    # Re-calculate fluency score\n",
    "    fluency_score = sum([x * y for (x, y) in zip(fluency_scores, durations)]) / sum(durations)\n",
    "    # Calculate whole completeness score\n",
    "    completeness_score = len([w for w in recognized_words if w.error_type == \"None\"]) / len(reference_words) * 100\n",
    "    completeness_score = completeness_score if completeness_score <= 100 else 100\n",
    "\n",
    "    print('    Paragraph accuracy score: {}, prosody score: {}, completeness score: {}, fluency score: {}'.format(\n",
    "        accuracy_score, prosody_score, completeness_score, fluency_score\n",
    "    ))\n",
    "\n",
    "    for idx, word in enumerate(final_words):\n",
    "        print('    {}: word: {}\\taccuracy score: {}\\terror type: {};'.format(\n",
    "            idx + 1, word.word, word.accuracy_score, word.error_type\n",
    "        ))\n",
    "\n",
    "\n",
    "def pronunciation_assessment_from_stream():\n",
    "    \"\"\"Performs pronunciation assessment asynchronously with input from an audio stream.\n",
    "        See more information at https://aka.ms/csspeech/pa\"\"\"\n",
    "\n",
    "    # Creates an instance of a speech config with specified subscription key and service region.\n",
    "    # Replace with your own subscription key and service region (e.g., \"westus\").\n",
    "    # Note: The sample is for en-US language.\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "\n",
    "    # Setup the audio stream\n",
    "    framerate, bits_per_sample, num_channels = read_wave_header(weatherfilename)\n",
    "    format = speechsdk.audio.AudioStreamFormat(samples_per_second=framerate, bits_per_sample=bits_per_sample, channels=num_channels)\n",
    "    stream = speechsdk.audio.PushAudioInputStream(format)\n",
    "    audio_config = speechsdk.audio.AudioConfig(stream=stream)\n",
    "\n",
    "    reference_text = \"What's the weather like?\"\n",
    "    # Create pronunciation assessment config, set grading system, granularity and if enable miscue based on your requirement.\n",
    "    pronunciation_config = speechsdk.PronunciationAssessmentConfig(\n",
    "        reference_text=reference_text,\n",
    "        grading_system=speechsdk.PronunciationAssessmentGradingSystem.HundredMark,\n",
    "        granularity=speechsdk.PronunciationAssessmentGranularity.Phoneme,\n",
    "        enable_miscue=True)\n",
    "    pronunciation_config.enable_prosody_assessment()\n",
    "\n",
    "    # Create a speech recognizer using a file as audio input.\n",
    "    language = 'en-US'\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, language=language, audio_config=audio_config)\n",
    "    # Apply pronunciation assessment config to speech recognizer\n",
    "    pronunciation_config.apply_to(speech_recognizer)\n",
    "\n",
    "    # Start push stream writer thread\n",
    "    push_stream_writer_thread = threading.Thread(target=push_stream_writer, args=[stream])\n",
    "    push_stream_writer_thread.start()\n",
    "    result = speech_recognizer.recognize_once_async().get()\n",
    "    push_stream_writer_thread.join()\n",
    "\n",
    "    # Check the result\n",
    "    if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "        print('pronunciation assessment for: {}'.format(result.text))\n",
    "        pronunciation_result = speechsdk.PronunciationAssessmentResult(result)\n",
    "        print('    Accuracy score: {}, prosody score: {}, pronunciation score: {}, completeness score : {}, fluency score: {}'.format(\n",
    "            pronunciation_result.accuracy_score, pronunciation_result.prosody_score, pronunciation_result.pronunciation_score,\n",
    "            pronunciation_result.completeness_score, pronunciation_result.fluency_score\n",
    "        ))\n",
    "        print('  Word-level details:')\n",
    "        for idx, word in enumerate(pronunciation_result.words):\n",
    "            print('    {}: word: {}\\taccuracy score: {}\\terror type: {};'.format(\n",
    "                idx + 1, word.word, word.accuracy_score, word.error_type\n",
    "            ))\n",
    "    elif result.reason == speechsdk.ResultReason.NoMatch:\n",
    "        print(\"No speech could be recognized\")\n",
    "    elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = result.cancellation_details\n",
    "        print(\"Speech Recognition canceled: {}\".format(cancellation_details.reason))\n",
    "        if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "\n",
    "\n",
    "def pronunciation_assessment_configured_with_json():\n",
    "    \"\"\"Performs pronunciation assessment asynchronously with input from an audio file.\n",
    "        See more information at https://aka.ms/csspeech/pa\"\"\"\n",
    "\n",
    "    # Creates an instance of a speech config with specified subscription key and service region.\n",
    "    # Replace with your own subscription key and service region (e.g., \"westus\").\n",
    "    # Note: The sample is for en-US language.\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "    audio_config = speechsdk.audio.AudioConfig(filename=weatherfilename)\n",
    "\n",
    "    reference_text = \"What's the weather like?\"\n",
    "    # Create pronunciation assessment config with json string (JSON format is not recommended)\n",
    "    enable_miscue, enable_prosody = True, True\n",
    "    config_json = {\n",
    "        \"GradingSystem\": \"HundredMark\",\n",
    "        \"Granularity\": \"Phoneme\",\n",
    "        \"Dimension\": \"Comprehensive\",\n",
    "        \"ScenarioId\": \"\",  # \"\" is the default scenario or ask product team for a customized one\n",
    "        \"EnableMiscue\": enable_miscue,\n",
    "        \"EnableProsodyAssessment\": enable_prosody,\n",
    "        \"NBestPhonemeCount\": 0,  # > 0 to enable \"spoken phoneme\" mode, 0 to disable\n",
    "    }\n",
    "    pronunciation_config = speechsdk.PronunciationAssessmentConfig(json_string=json.dumps(config_json))\n",
    "    pronunciation_config.reference_text = reference_text\n",
    "\n",
    "    # Create a speech recognizer using a file as audio input.\n",
    "    language = 'en-US'\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, language=language, audio_config=audio_config)\n",
    "    # Apply pronunciation assessment config to speech recognizer\n",
    "    pronunciation_config.apply_to(speech_recognizer)\n",
    "\n",
    "    result = speech_recognizer.recognize_once_async().get()\n",
    "\n",
    "    # Check the result\n",
    "    if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "        print('pronunciation assessment for: {}'.format(result.text))\n",
    "        pronunciation_result = json.loads(result.properties.get(speechsdk.PropertyId.SpeechServiceResponse_JsonResult))\n",
    "        print('assessment results:\\n{}'.format(json.dumps(pronunciation_result, indent=4)))\n",
    "    elif result.reason == speechsdk.ResultReason.NoMatch:\n",
    "        print(\"No speech could be recognized\")\n",
    "    elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = result.cancellation_details\n",
    "        print(\"Speech Recognition canceled: {}\".format(cancellation_details.reason))\n",
    "        if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "\n",
    "\n",
    "def pronunciation_assessment_with_content_assessment():\n",
    "    \"\"\"Performs content assessment asynchronously with input from an audio file.\n",
    "        See more information at https://aka.ms/csspeech/pa\"\"\"\n",
    "\n",
    "    # Create an instance of a speech config with specified subscription key and service region.\n",
    "    # Replace with your own subscription key and service region (e.g., \"westus\").\n",
    "    # Note: The sample is for en-US language.\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "    # Generally, the waveform should longer than 20s and the content should be more than 3 sentences.\n",
    "    audio_config = speechsdk.audio.AudioConfig(filename=seasonsfilename)\n",
    "\n",
    "    # Create pronunciation assessment config, set grading system, granularity and if enable miscue based on your requirement.\n",
    "    topic = \"the season of the fall\"\n",
    "    pronunciation_config = speechsdk.PronunciationAssessmentConfig(\n",
    "        grading_system=speechsdk.PronunciationAssessmentGradingSystem.HundredMark,\n",
    "        granularity=speechsdk.PronunciationAssessmentGranularity.Phoneme,\n",
    "        enable_miscue=False)\n",
    "    pronunciation_config.enable_prosody_assessment()\n",
    "    pronunciation_config.enable_content_assessment_with_topic(topic)\n",
    "\n",
    "    # Create a speech recognizer using a file as audio input.\n",
    "    language = 'en-US'\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(\n",
    "        speech_config=speech_config, language=language, audio_config=audio_config)\n",
    "    # Apply pronunciation assessment config to speech recognizer\n",
    "    pronunciation_config.apply_to(speech_recognizer)\n",
    "\n",
    "    done = False\n",
    "    pron_results = []\n",
    "    recognized_text = \"\"\n",
    "\n",
    "    def stop_cb(evt):\n",
    "        \"\"\"callback that signals to stop continuous recognition upon receiving an event `evt`\"\"\"\n",
    "        print(\"CLOSING on {}\".format(evt))\n",
    "        nonlocal done\n",
    "        done = True\n",
    "\n",
    "    def recognized(evt):\n",
    "        nonlocal pron_results, recognized_text\n",
    "        if (evt.result.reason == speechsdk.ResultReason.RecognizedSpeech or evt.result.reason == speechsdk.ResultReason.NoMatch):\n",
    "            pron_results.append(speechsdk.PronunciationAssessmentResult(evt.result))\n",
    "            if evt.result.text.strip().rstrip(\".\") != \"\":\n",
    "                print(f\"Recognizing: {evt.result.text}\")\n",
    "                recognized_text += \" \" + evt.result.text.strip()\n",
    "\n",
    "    # Connect callbacks to the events fired by the speech recognizer\n",
    "    speech_recognizer.recognized.connect(recognized)\n",
    "    speech_recognizer.session_started.connect(lambda evt: print(\"SESSION STARTED: {}\".format(evt)))\n",
    "    speech_recognizer.session_stopped.connect(lambda evt: print(\"SESSION STOPPED {}\".format(evt)))\n",
    "    speech_recognizer.canceled.connect(lambda evt: print(\"CANCELED {}\".format(evt)))\n",
    "    # Stop continuous recognition on either session stopped or canceled events\n",
    "    speech_recognizer.session_stopped.connect(stop_cb)\n",
    "    speech_recognizer.canceled.connect(stop_cb)\n",
    "\n",
    "    # Start continuous pronunciation assessment\n",
    "    speech_recognizer.start_continuous_recognition()\n",
    "    while not done:\n",
    "        time.sleep(.5)\n",
    "    speech_recognizer.stop_continuous_recognition()\n",
    "\n",
    "    # Content assessment result is in the last pronunciation assessment block\n",
    "    assert pron_results[-1].content_assessment_result is not None\n",
    "    content_result = pron_results[-1].content_assessment_result\n",
    "    print(f\"Content Assessment for: {recognized_text.strip()}\")\n",
    "    print(\"Content Assessment results:\\n\"\n",
    "          f\"\\tGrammar score: {content_result.grammar_score:.1f}\\n\"\n",
    "          f\"\\tVocabulary score: {content_result.vocabulary_score:.1f}\\n\"\n",
    "          f\"\\tTopic score: {content_result.topic_score:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5a6ed70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognition is running....\n",
      "Recognized:               ?\n"
     ]
    }
   ],
   "source": [
    "in_key = speech_key\n",
    "in_region = speech_region\n",
    "in_file = \"41.wav\"\n",
    "lang = \"hi-IN\"\n",
    "speech_recognize_async_from_file(in_key, in_region, in_file, lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa2d0b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
